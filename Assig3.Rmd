---
title: "MIS40970 Data Mining - Assignment 3 Classification"
output:
  html_notebook: default
  pdf_document: default
---
```{r}
#rm() is used to remove other objects from the environment
rm(list=ls())

#To check the working directory
getwd()
#A specific working drectory needs to be set for the loading of dataset
setwd("G:/R_programs_git/R_Progams/Classification/Classification")

```
## **Q2 Describe what this piece of R code is doing and why it is an important starting point for running classification algorithm. 
##> set.seed(1234)
##> dataPartition <- sample(2,nrow(data),replace=TRUE,prob=c(0.7,0.3))
##> trainData <- data[dataPartition ==1,]
##> testData <- [dataPartition ==2,]**

Classification needs supervised learning where we need to partition the data which can be used to train dataset. To explain the above set of commands, data has been imported from college.csv file as shown below:
```{r}
#Importing library readr to load data from csv file
library(readr)

#Importing data from CSV in a variable college
college <- read_csv("G:/R_programs_git/R_Progams/Classification/Classification/college.csv")

set.seed(1234)
dataPartition <- sample(2,nrow(college),replace=TRUE,prob=c(0.7,0.3))
trainCollege <- college[dataPartition ==1,]
testCollege <- college[dataPartition ==2,]
```
For the first statement(**set.seed(1234)**), we use seed number as a starting point that is used to generate a sequence of pseudo random numbers. This function is important if there is need that results should be reproducible and debuggable easily. 

Second statement(**dataPartition<-sample(2,nrow(data),replace=TRUE,prob=c(0.7,0.3))**) represents the properties of the partitions that need to be taken. Sample function takes a specified size from 2(an integer vector that can take one or more elements) so that function can generate random permutation of elements of vector(1:vector). If vector is 4, then the random permutation sequence will take numbers between 1 and 4 numbers. nrow(data) represents the size giving the numbers of items to choose and nrow is the last row of the college dataset. replace represents whether the sampling should be done with replacement or without replacement. Replace=TRUE is set to do the sampling with replacement. And prob will take probability weights for obtaining sampled elements. So it is expected that 1 will appear more than 2 times as weight is 0.7 than 0.3. If we write prob=c(0.3,0.5,0.2) then 1 is appeared to be less times than 2 but more than 3. 

**trainCollege <- college[dataPartition ==1,] and testCollege <- college[dataPartition ==2,]** split the college dataset into 2 datasets i.e. Test data and Train data, where test data is used for testing. 

All these commands will help in creating training dataset that can be changed continuously that help in formulation of classification algorithms. 

## **Q3 What is the role of the M parameter in the Weka implementation of C4.5 algorithm? Which part of the DTL induction process does this parameter affect?**


## **Q4. Install	R	package	"C50".	Import	customer	churn	dataset	(churn)	using	data() function. Examine	the	churnTrain dataset. Using	R	run	a	decision-tree	classification	algorithm	of	your choice	constructing	a	full	unpruned	tree	and	a	pruned	tree.	Compare	classification	results	of the	pruned	and	unpruned	trees generated.**	
```{r}
install.packages('C50')

library(C50)

#To examine datasets in package C50
data()
```
After examining data function, it has been found out that there are two datasets in 'Customer Churn Data' (C50 package), which are churnTest and churnTrain. To import datasets in C50 package, use command "data(churn)".
```{r}
data(churn)
print("Details of attributes in churnTrain")
print("___________________________________")
str(churnTrain)

print("---------------------------Summary Table :churnTrain---------------------")
#To understand dataset churnTrain
summary(churnTrain)

churnTrain <- churnTrain[,c(-1,-4)]
print("Details of attributes in churnTrain after selecting few columns")
print("_______________________________________________________________")
str(churnTrain)
```
```{r}
set.seed(1234)
dataPart <- sample(2, nrow(churnTrain),replace = TRUE,prob = c(0.7,0.3))
traindata <- churnTrain[dataPart ==1,]
testdata <- churnTrain[dataPart ==2,]

#Installing package 'tree' for Decision Tree

install.packages("tree")

library(tree)

```
```{r}
#Grow a tree using tree to predict customer churn for all other independent variables

fit <- tree(traindata$churn ~ .,traindata)

#To print detailed summary of splits
summary(fit)
cat("\n \n")

#Prediction using predict function for both traindata and testdata
traindata_C50 = predict(fit,traindata,type="class")
testdata_C50 = predict(fit,testdata,type="class")

#Printing prediction result using table
print("Prediction of traindata")
cat("_______________________\n")
table(traindata_C50,traindata$churn)
cat("\n")

print("Prediction of testdata")
cat("______________________\n")
table(testdata_C50,testdata$churn)

#To plot the tree
plot(fit)
text(fit, all = TRUE, cex = 0.5)
```
```{r}
#Pruning the tree
pfit = cv.tree(fit,FUN = prune.misclass)
print("Details of prune.misclass")
print("_________________________")
cat("\n")
pfit

pruneData = prune.misclass(fit,best=6)
#Plot the pruned tree
plot(pruneData)
text(pruneData,all = TRUE, cex = 0.5)

pruneData2 = prune.misclass(fit,best=2)
#Plot the pruned tree
plot(pruneData2)
text(pruneData2,all = TRUE, cex = 0.7)
```
Pruning the decision tree will help to avoid overfitting the data. It will minimize the cross validation error (uing xerror) and select complexity parameter that is associated with least error. Results shows that unpruned tree is larger because the algorithm is implemented as is. While in pruned tree, there is an additional step which analyse which nodes or branches to be removed that will not affect the performance of decision tree. 

## **Q5 Compare generalisation performance of the pruned and unpruned tree from Q4. Output relevant summaries and confusion matrices. Describe the results.**

```{r}
print("Summary of pruned tree with best 6")
cat("\n")
summary(pruneData)

cat("\n___________________________________________________________________")
cat("\n")
print("Summary of pruned tree with best 2")
cat("\n")
summary(pruneData2)

cat("\n___________________________________________________________________")
cat("\n")
print("Summary of unpruned tree")
cat("\n")
summary(fit)

```
Classification on C50 dataset has been done using **tree** package to predict whether the cutomer will churn or not. From the above summary data **Misclassification error rate** for pruned decision tree with best 2 and for pruned decision tree with best 6 are 42% and 12% bigger than unpruned decision tree respectively. Whereas **residual mean deviance** for pruned decision tree with best 2 and pruned decision tree with best 6 are 30% and 43%lower than unpruned decision tree respectively. This suggests that unpruned decision tree classification is better for training data. Also, as pruned decision tree is easy to understand because it has less risk of overfitting data. If we increase the best parameter to 13 then the pruned tree will be similar to that of unpruned classification. 

```{r}
prune13 = prune.misclass(fit, best = 13)
plot(prune13)
text(prune13,all = TRUE, cex = 0.5)

summary(prune13)
```
**Confusion Matrix** counts the number of times predicted variable has been mapped to other true variables. 
```{r}
library(caret)

print("Confusion Matrix of Unpruned decision tree of training dataset")
cat("\n")

p1 = predict(fit,churnTrain,type="class")
unp_table = table(p1,churnTrain$churn)
cat("\n")

confusionMatrix(unp_table)
```

```{r}
print("Confusion Matrix of Unpruned decision tree of test dataset")
cat("\n")

p2 = predict(fit,churnTest,type="class")
unp2_table = table(p2,churnTest$churn)
cat("\n")

confusionMatrix(unp2_table)

```
```{r}
print("Confusion Matrix of pruned decision tree of training dataset")
cat("\n")

p3 = predict(pruneData,churnTrain,type="class")
p_table = table(p3,churnTrain$churn)
cat("\n")

confusionMatrix(p_table)

```
```{r}
print("Confusion Matrix of pruned decision tree of test dataset")
cat("\n")

p4 = predict(pruneData,churnTest,type="class")
p2_table = table(p4,churnTest$churn)
cat("\n")

confusionMatrix(p2_table)

```
```{r}
treeC50=tree(traindata$churn~.,traindata)
Train=predict(treeC50,traindata ,type="class") 
Test=predict(treeC50,testdata, type="class") 
table(Train,traindata$churn)    

```

```{r}
table(Test,testdata$churn)
```
From the above results we can see that there are 23 misidentified train data for YES and 73 for NO. If data will be more than an accurate model can be created.

## **Q6 Install R package “caret”. Import German credit rating dataset (GermanCredit). Examine the data. Use the data to build a classification model to predict “Good” or “Bad” customer credit rating. Pay attention to the model’s generalisation and its’ ability to correctly predict both classes. Interpret the results.**

```{r}
#Installing Caret package
install.packages("caret")

library(caret)
```

```{r}
#Importing dataset GermanCredit
data("GermanCredit")
print("Summary of German Credit")
cat("\n")
str(GermanCredit)
#Creating Trained and test dataset

set.seed(123)

GermanCredit <- GermanCredit[,!names(GermanCredit) %in% c("Duration","Amount","account_length")]

partition <- sample(2,nrow(GermanCredit),replace = TRUE,prob = c(0.7,0.3))
trainGC <- GermanCredit[partition ==1,]
testGC <- GermanCredit[partition ==2,]

cat("\n \n \n")
print("Summary of dataset")
cat("\n")
summary(GermanCredit)
```
```{r}
print("Printing dimensions of Trained and Test dataset created")
print("_________________________Train Dataset_________________")
dim(trainGC)

print("_________________________Test  Dataset_________________")
dim(testGC)

```
```{r}
library(tree)

#Unprunned dataset of GermanCredit

unp_fit = tree(trainGC$Class~.,trainGC)

print("Summary of classification of German Credit")
cat("\n")
summary(unp_fit)
```
```{r}
plot(unp_fit)
text(unp_fit,all=TRUE,cex = 0.6)
```
```{r}
#Confusion Matrix
pGC = predict(unp_fit,trainGC,type = "class")
p_table = table(pGC, trainGC$Class)
print(p_table)
```
```{r}
print("Confusion Matrix for trained German Credit dataset")
cat("\n")
confusionMatrix(p_table)
```
```{r}
pGC1 = predict(unp_fit,testGC,type = "class")
p1_table = table(pGC1, testGC$Class)
print(p1_table)
```
```{r}
print("Confusion Matrix for test German Credit dataset")
cat("\n")
confusionMatrix(p1_table)
```
```{r}
plot(trainGC$CreditHistory.PaidDuly~trainGC$EmploymentDuration.Unemployed,pch=21,main="Plot between Credit history and eomplyment duration",xlab="Unemployed", ylab ="Paid Duly",bg=c("green","yellow") [unclass(trainGC$Class)])

#Pruned tree
cv_German=cv.tree(unp_fit,FUN=prune.misclass)
print(cv_German)
 plot(cv_German$size,cv_German$dev,type="b",xlab = "Size",ylab = "Dev",main = "Plot between Size and Dev")
```
```{r}
prune_GC = prune.misclass(unp_fit,best=2)
summary(prune_GC)

plot(prune_GC)
text(prune_GC,all=TRUE,cex = 0.6)
```
As from the summary results of pruned and unpruned decision tree, we can see that Misclassification error rate is same for both the tree types. However, residual mean deviance is larger and unpruned tree is better fit and helps in understanding more than pruned tree.

## **Q7 Load file college.csv provided on Blackboard. Explore the data. Prepare the data for analysis. Use three different classification algorithms to classify colleges into two classes based on the label ("Not Elite", "Elite") (at least one algorithm of the type decision tree). 1. Describe what you have learned about the dataset and classification results. 2. What classification algorithm(s) did you use, with what parameter settings and how these settings affected the algorithm(s) performance? 3. Exclude the class labels from the data and explore this dataset with clustering. Compare clustering results with results of classification.**

