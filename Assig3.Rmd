---
title: "MIS40970 Data Mining - Assignment 3 Classification"
output:
  pdf_document: default
  html_notebook: default
---
```{r}
#rm() is used to remove other objects from the environment
rm(list=ls())

#To check the working directory
getwd()
#A specific working drectory needs to be set for the loading of dataset
setwd("G:/R_programs_git/R_Progams/Classification/Classification")

```
## **Q1 Compare and contrast classification and clustering.**

## **Q2 Describe what this piece of R code is doing and why it is an important starting point for running classification algorithm. 
##> set.seed(1234)
##> dataPartition <- sample(2,nrow(data),replace=TRUE,prob=c(0.7,0.3))
##> trainData <- data[dataPartition ==1,]
##> testData <- [dataPartition ==2,]**

Classification needs supervised learning where we need to partition the data which can be used to train dataset. To explain the above set of commands, data has been imported from college.csv file as shown below:
```{r}
#Importing library readr to load data from csv file
library(readr)

#Importing data from CSV in a variable college
college <- read_csv("G:/R_programs_git/R_Progams/Classification/Classification/college.csv")

set.seed(1234)
dataPartition <- sample(2,nrow(college),replace=TRUE,prob=c(0.7,0.3))
trainCollege <- college[dataPartition ==1,]
testCollege <- college[dataPartition ==2,]
```
For the first statement(**set.seed(1234)**), we use seed number as a starting point that is used to generate a sequence of pseudo random numbers. This function is important if there is need that results should be reproducible and debuggable easily. 

Second statement(**dataPartition<-sample(2,nrow(data),replace=TRUE,prob=c(0.7,0.3))**) represents the properties of the partitions that need to be taken. Sample function takes a specified size from 2(an integer vector that can take one or more elements) so that function can generate random permutation of elements of vector(1:vector). If vector is 4, then the random permutation sequence will take numbers between 1 and 4 numbers. nrow(data) represents the size giving the numbers of items to choose and nrow is the last row of the college dataset. replace represents whether the sampling should be done with replacement or without replacement. Replace=TRUE is set to do the sampling with replacement. And prob will take probability weights for obtaining sampled elements. So it is expected that 1 will appear more than 2 times as weight is 0.7 than 0.3. If we write prob=c(0.3,0.5,0.2) then 1 is appeared to be less times than 2 but more than 3. 

**trainCollege <- college[dataPartition ==1,] and testCollege <- college[dataPartition ==2,]** split the college dataset into 2 datasets i.e. Test data and Train data, where test data is used for testing. 

All these commands will help in creating training dataset that can be changed continuously that help in formulation of classification algorithms. 

## **Q3 What is the role of the M parameter in the Weka implementation of C4.5 algorithm? Which part of the DTL induction process does this parameter affect?**

While implementing C4.5 algorithm in Weka software, M parameter sets a minimum instances per leaf that effects the separation of data on the decision tree. Minimum of the instances have atleast two branches will be at each split.As a result, there will be effect on the total number of tree formulated.
```{r}
#Installing Weka package

#install.packages("RWeka")
```



## **Q4. Install	R	package	"C50".	Import	customer	churn	dataset	(churn)	using	data() function. Examine	the	churnTrain dataset. Using	R	run	a	decision-tree	classification	algorithm	of	your choice	constructing	a	full	unpruned	tree	and	a	pruned	tree.	Compare	classification	results	of the	pruned	and	unpruned	trees generated.**	
```{r}
#install.packages('C50')

library(C50)

#To examine datasets in package C50
data()
```
After examining data function, it has been found out that there are two datasets in 'Customer Churn Data' (C50 package), which are churnTest and churnTrain. To import datasets in C50 package, use command "data(churn)".
```{r}
data(churn)
print("Details of attributes in churnTrain")
print("___________________________________")
str(churnTrain)

print("---------------------------Summary Table :churnTrain---------------------")
#To understand dataset churnTrain
summary(churnTrain)

churnTrain <- churnTrain[,c(-1,-4)]
print("Details of attributes in churnTrain after selecting few columns")
print("_______________________________________________________________")
str(churnTrain)
```
```{r}

set.seed(34)
dataPart <- sample(2, nrow(churnTrain),replace = TRUE,prob = c(0.7,0.3))
traindata <- churnTrain[dataPart ==1,]
testdata <- churnTrain[dataPart ==2,]

#Installing package 'tree' for Decision Tree

install.packages("tree")

library(tree)

```
```{r}
#Grow a tree using tree to predict customer churn for all other independent variables

fit <- tree(traindata$churn ~ .,traindata)

#To print detailed summary of splits
summary(fit)
cat("\n \n")

#Prediction using predict function for both traindata and testdata
traindata_C50 = predict(fit,traindata,type="class")
testdata_C50 = predict(fit,testdata,type="class")

#Printing prediction result using table
print("Prediction of traindata")
cat("_______________________\n")
table(traindata_C50,traindata$churn)
cat("\n")

print("Prediction of testdata")
cat("______________________\n")
table(testdata_C50,testdata$churn)

#To plot the tree
plot(fit)
text(fit, all = TRUE, cex = 0.5)
```
```{r}
#Pruning the tree
pfit = cv.tree(fit,FUN = prune.misclass)
print("Details of prune.misclass")
print("_________________________")
cat("\n")
pfit

pruneData = prune.misclass(fit,best=6)
#Plot the pruned tree
plot(pruneData)
text(pruneData,all = TRUE, cex = 0.5)

pruneData2 = prune.misclass(fit,best=2)
#Plot the pruned tree
plot(pruneData2)
text(pruneData2,all = TRUE, cex = 0.7)
```
Pruning the decision tree will help to avoid overfitting the data. It will minimize the cross validation error (uing xerror) and select complexity parameter that is associated with least error. Results shows that unpruned tree is larger because the algorithm is implemented as is. While in pruned tree, there is an additional step which analyse which nodes or branches to be removed that will not affect the performance of decision tree. 

## **Q5 Compare generalisation performance of the pruned and unpruned tree from Q4. Output relevant summaries and confusion matrices. Describe the results.**

```{r}
print("Summary of pruned tree with best 6")
cat("\n")
summary(pruneData)

cat("\n___________________________________________________________________")
cat("\n")
print("Summary of pruned tree with best 2")
cat("\n")
summary(pruneData2)

cat("\n___________________________________________________________________")
cat("\n")
print("Summary of unpruned tree")
cat("\n")
summary(fit)

```
Classification on C50 dataset has been done using **tree** package to predict whether the cutomer will churn or not. From the above summary data **Misclassification error rate** for pruned decision tree with best 2 and for pruned decision tree with best 6 are 42% and 12% bigger than unpruned decision tree respectively. Whereas **residual mean deviance** for pruned decision tree with best 2 and pruned decision tree with best 6 are 30% and 43%lower than unpruned decision tree respectively. This suggests that unpruned decision tree classification is better for training data. Also, as pruned decision tree is easy to understand because it has less risk of overfitting data. If we increase the best parameter to 13 then the pruned tree will be similar to that of unpruned classification. 

```{r}
prune13 = prune.misclass(fit, best = 13)
plot(prune13)
text(prune13,all = TRUE, cex = 0.5)

summary(prune13)
```
**Confusion Matrix** counts the number of times predicted variable has been mapped to other true variables. 
```{r}
library(caret)

print("Confusion Matrix of Unpruned decision tree of training dataset")
cat("\n")

p1 = predict(fit,churnTrain,type="class")
unp_table = table(p1,churnTrain$churn)
cat("\n")

confusionMatrix(unp_table)
```

```{r}
print("Confusion Matrix of Unpruned decision tree of test dataset")
cat("\n")

p2 = predict(fit,churnTest,type="class")
unp2_table = table(p2,churnTest$churn)
cat("\n")

confusionMatrix(unp2_table)

```
```{r}
print("Confusion Matrix of pruned decision tree of training dataset")
cat("\n")

p3 = predict(pruneData,churnTrain,type="class")
p_table = table(p3,churnTrain$churn)
cat("\n")

confusionMatrix(p_table)

```
```{r}
print("Confusion Matrix of pruned decision tree of test dataset")
cat("\n")

p4 = predict(pruneData,churnTest,type="class")
p2_table = table(p4,churnTest$churn)
cat("\n")

confusionMatrix(p2_table)

```
```{r}
treeC50=tree(traindata$churn~.,traindata)
Train=predict(treeC50,traindata ,type="class") 
Test=predict(treeC50,testdata, type="class") 
table(Train,traindata$churn)    

```

```{r}
table(Test,testdata$churn)
```
From the above results we can see that there are 23 misidentified train data for YES and 73 for NO. If data will be more than an accurate model can be created.

## **Q6 Install R package “caret”. Import German credit rating dataset (GermanCredit). Examine the data. Use the data to build a classification model to predict “Good” or “Bad” customer credit rating. Pay attention to the model’s generalisation and its’ ability to correctly predict both classes. Interpret the results.**

```{r}
#Installing Caret package
install.packages("caret")

library(caret)
```

```{r}
#Importing dataset GermanCredit
data("GermanCredit")
print("Summary of German Credit")
cat("\n")
str(GermanCredit)
#Creating Trained and test dataset

set.seed(123)

GermanCredit <- GermanCredit[,!names(GermanCredit) %in% c("Duration","Amount","account_length")]

partition <- sample(2,nrow(GermanCredit),replace = TRUE,prob = c(0.7,0.3))
trainGC <- GermanCredit[partition ==1,]
testGC <- GermanCredit[partition ==2,]

cat("\n \n \n")
print("Summary of dataset")
cat("\n")
summary(GermanCredit)
```
```{r}
print("Printing dimensions of Trained and Test dataset created")
print("_________________________Train Dataset_________________")
dim(trainGC)

print("_________________________Test  Dataset_________________")
dim(testGC)

```
```{r}
library(tree)

#Unprunned dataset of GermanCredit

unp_fit = tree(trainGC$Class~.,trainGC)

print("Summary of classification of German Credit")
cat("\n")
summary(unp_fit)
```
```{r}
plot(unp_fit)
text(unp_fit,all=TRUE,cex = 0.6)
```
```{r}
#Confusion Matrix
pGC = predict(unp_fit,trainGC,type = "class")
p_table = table(pGC, trainGC$Class)
print(p_table)
```
```{r}
print("Confusion Matrix for trained German Credit dataset")
cat("\n")
confusionMatrix(p_table)
```
```{r}
pGC1 = predict(unp_fit,testGC,type = "class")
p1_table = table(pGC1, testGC$Class)
print(p1_table)
```
```{r}
print("Confusion Matrix for test German Credit dataset")
cat("\n")
confusionMatrix(p1_table)
```
```{r}
plot(trainGC$CreditHistory.PaidDuly~trainGC$EmploymentDuration.Unemployed,pch=21,main="Plot between Credit history and eomplyment duration",xlab="Unemployed", ylab ="Paid Duly",bg=c("green","yellow") [unclass(trainGC$Class)])

#Pruned tree
cv_German=cv.tree(unp_fit,FUN=prune.misclass)
print(cv_German)
 plot(cv_German$size,cv_German$dev,type="b",xlab = "Size",ylab = "Dev",main = "Plot between Size and Dev")
```
```{r}
prune_GC = prune.misclass(unp_fit,best=2)
summary(prune_GC)

plot(prune_GC)
text(prune_GC,all=TRUE,cex = 0.6)
```
As from the summary results of pruned and unpruned decision tree, we can see that Misclassification error rate is same for both the tree types. However, residual mean deviance is larger and unpruned tree is better fit and helps in understanding more than pruned tree.

## **Q7 Load file college.csv provided on Blackboard. Explore the data. Prepare the data for analysis. Use three different classification algorithms to classify colleges into two classes based on the label ("Not Elite", "Elite") (at least one algorithm of the type decision tree). 1. Describe what you have learned about the dataset and classification results. 2. What classification algorithm(s) did you use, with what parameter settings and how these settings affected the algorithm(s) performance? 3. Exclude the class labels from the data and explore this dataset with clustering. Compare clustering results with results of classification.**

```{r}
library(readr)

cdata <- read_csv("G:/R_programs_git/R_Progams/Classification/Classification/college.csv", col_types = cols(Private = col_factor(levels = c("Yes","No")), isElite = col_factor(levels = c("Elite","Not Elite"))), na = "0")

View(cdata)
```
Now we will ue descriptive analytics to understand insights about dataset College (cdata).
```{r}
cat("\n \n")
print("Summary of dataset")
cat("\n")
summary(cdata)

cat("\n \n")
print("Attributes of dataset")
cat("\n")
attributes(cdata)
```

```{r}
print("Summary of isElite column")
cat("\n")
summary(cdata$isElite)
```
From summary table of descriptive analytics we can know the basic statistics such as mean,median, range, etc. We can generate the summary table by two ways as discussed below :
```{r}
df <- unique(cdata[c(3:6)])
Des_stats <- do.call(data.frame,
                    list(Average = apply(df, 2, mean),
                    Standard_Deviation = apply(df, 2, sd),
                    Median = apply(df, 2, median),
                    Minimum = apply(df, 2, min),
                    Maximum = apply(df, 2, max)))

print(Des_stats)
```
To see more details we can generate correlation methods so that we can establish the mutual relationship amongst variables and we can forsee the trends among different variables. Correlation plot can be generated by creating scatterplot matrix. There are two methods through which we can generate a scatterplot matrix described as follow:
```{r}
corr = cor(df,use = "complete.obs",method="kendall")
print(round(corr,digits = 3))

library(s20x)
pairs(df,col="green",pch=20)
pairs20x(df)
```
Before applying classification algorithm to any dataset, first we need to create reusable partitions.

```{r}
set.seed(8)

set <- cdata[-2]
partitiondata <- sample(2, nrow(set),replace=TRUE,prob=c(0.7,0.3))
trainData <- set[partitiondata ==1,]
testData <- set[partitiondata ==2,]

print("Train Data")
dim(trainData)

cat("\n")
print("Test Data")
dim(testData)
```
By using histograms and density curve, we can interpret the distribution of
the demographic and competitive variables whether the distribution is normal distribution or not.

```{r}
qplot(accept_rate, Outstate, colour=isElite, data=trainData)
par(mfrow=c(1,2))

hist(trainData$accept_rate, main = "Accept Rate",xlab = "Accept Rate")
hist(trainData$Enroll, main = "Enroll",xlab = "Enroll")
hist(trainData$Grad.Rate, main = "Grad Rate",xlab = "Grad Rate")
hist(trainData$Outstate, main="Outstate",xlab = "Outstate")
```






**Classification using Tree**
```{r}
library(tree)

tree.trainData = tree(trainData$isElite~.,trainData)
print("Summary of tree using TREE")
cat("\n")
summary(tree.trainData)
```
```{r}
plot(tree.trainData)
text(tree.trainData, all = TRUE, cex = 0.45)
```
```{r}
#Confusion Matrix of trained data
confusionMatrix(table(predict(tree.trainData,trainData,type = "class"),trainData$isElite))
```
```{r}
#Confusion Matrix of test data
confusionMatrix(table(predict(tree.trainData,testData,type = "class"),testData$isElite))
```
```{r}
plot(trainData$Enroll~trainData$Grad.Rate,pch=21,main="Plot between Grad Rate and Enroll",xlab = "Grad Rate",ylab = "Enroll", bg=c("green","red","yellow")[unclass(trainData$isElite)])

plot(trainData$accept_rate~trainData$Outstate,pch=21,main="Plot between Accept Rate and Outstate",xlab = "Outstate",ylab = "Accept Rate", bg=c("green","red","yellow")[unclass(trainData$isElite)])


```
```{r}
#Pruned Data

p.tree = prune.misclass(tree.trainData,best=2)
print("Summary of pruned decision tree with best 2")
summary(p.tree)
```
```{r}
plot(p.tree)
text(p.tree, all=TRUE, cex = 0.8)
```
From unpruned and pruned decision tree, we can see that Misclassification error rate is 37% bigger than unpruned tree and residual mean deviance is almost 50% lesser than unpruned tree. So unpruned tree is a better fitment. 

```{r}
#Confusion Matrix of train data of pruned tree
confusionMatrix(table(predict(p.tree,trainData,type = "class"),trainData$isElite))
```
```{r}
#Confusion Matrix of test data of pruned tree
confusionMatrix(table(predict(p.tree,testData,type = "class"),testData$isElite))
```
From statistics of pruned decision tree, we can see that there are 11 misidentified elements in test data for Elite and 10 for Not Elite. 
```{r}
cv1=cv.tree(tree.trainData,FUN=prune.misclass)
par(mfrow=c(1,2))
plot(cv1$size,cv1$dev,type="b",xlab = "Size",ylab = "Dev",main = "Plot Dev vs Size")

par(mfrow=c(1,2))
plot(cv1$k,cv1$dev,type="b",xlab = "K",ylab = "Dev",main = "Plot K vs Size")
```

**Random Forest Classification**
```{r}
library(randomForest)

random.tree <- randomForest(isElite~.,data=trainData, importance = TRUE,tree=2500)
print(random.tree)

varImpPlot(random.tree)
```
```{r}
pdata <- predict(random.tree, testData)
print("Summary of prediction data")
summary(pdata)

cat("\n")
print("Summary of isElite")
summary(testData$isElite)

cat("\n\n")
confusionMatrix(table(pdata,testData$isElite))
```
```{r}
plot(random.tree)
importance(random.tree)
```
```{r}
library(party)

set.seed(1234)
r.tree <- cforest(as.factor(isElite) ~ .,data=trainData, controls=cforest_unbiased(ntree=200,mtry=3))

prediction <- predict(r.tree,testData,OOB = TRUE,type="response")
summary(prediction)
```
```{r}
temp <- ctree(trainData$isElite~.,data=trainData)
plot(temp,main = "Decision Tree",cex = 0.5)
```
**Classification using Regression**
```{r}
library(rpart)

set.seed(145)
rp.tree <- rpart(isElite~.,data=trainData)

print("Summary of rpart decision tree")
cat("\n\n")
summary(rp.tree)

plotcp(rp.tree)
cat("\n")
printcp(rp.tree)

```
```{r}
plot(rp.tree, uniform=TRUE, main="Classification Tree for isElite")
text(rp.tree, use.n=TRUE, all=TRUE, cex=.8)
```
```{r}
#Pruning the tree
prp.tree <- prune(rp.tree, cp=rp.tree$cptable[which.min(rp.tree$cptable[,"xerror"]),"CP"])

plot(prp.tree, uniform=TRUE, main="Pruned Classification Tree for isElite")
text(prp.tree, use.n=TRUE, all=TRUE, cex=.8)

```
```{r}
par(mfrow=c(1,2))
rsq.rpart(rp.tree)
```
From all three algorithms used for classfication on college dataset, we can determine that random forest classification has highest accuracy compared to other two. Because random forest improves predictive accuracy which generates large number of bootstrapped trees, classifying each option using every tree in newly created forest whihc decides a final predicted result by aggregating all the results.

```{r}
library(factoextra)
library(ggplot2)

df <- na.omit(df)
df <- scale(df)
head(round(df,2))

set.seed(234)

km <- kmeans(df,2,nstart=25)

cat("____________________________________________________________________")
cat("\n\n")
print(km)

```
```{r}
fviz_cluster(km,data=df)

plot(df, col = km$cluster, pch = 19)
points(km$cluter, col = 1:2, pch = 8, cex = 3)
```
```{r}
#Hierarchial Clustering

#Creation of dissimilarity matrix
d <- dist(df,method = "euclidean")

#applying hclust() function
res_hc1 <- hclust(d, method = "ward.D2")

#Cutting groups into 4 clusters
grp1 <- cutree(res_hc1,k=4)

#Plotting the cluster
plot(res_hc1, cex = 0.6)
rect.hclust(res_hc1, k = 4, border = 2:5)

res.hc1 <- eclust(df, "hclust", k = 3, graph = FALSE)
fviz_silhouette(res.hc1)
```


