---
title: "MIS40970 Data Mining - Assignment 3 Classification"
output:
  html_notebook: default
  pdf_document: default
---
```{r}
#rm() is used to remove other objects from the environment
rm(list=ls())

#To check the working directory
getwd()
#A specific working drectory needs to be set for the loading of dataset
setwd("G:/R_programs_git/R_Progams/Classification/Classification")

```
##**Q2 Describe what this piece of R code is doing and why it is an important starting point for running classification algorithm. 
##> set.seed(1234)
##> dataPartition <- sample(2,nrow(data),replace=TRUE,prob=c(0.7,0.3))
##> trainData <- data[dataPartition ==1,]
##> testData <- [dataPartition ==2,]**

Classification needs supervised learning where we need to partition the data which can be used to train dataset. To explain the above set of commands, data has been imported from college.csv file as shown below:
```{r}
#Importing library readr to load data from csv file
library(readr)

#Importing data from CSV in a variable college
college <- read_csv("G:/R_programs_git/R_Progams/Classification/Classification/college.csv")

set.seed(1234)
dataPartition <- sample(2,nrow(college),replace=TRUE,prob=c(0.7,0.3))
trainCollege <- college[dataPartition ==1,]
testCollege <- college[dataPartition ==2,]
```






## **Q4. Install	R	package	"C50".	Import	customer	churn	dataset	(churn)	using	data() function. Examine	the	churnTrain dataset. Using	R	run	a	decision-tree	classification	algorithm	of	your choice	constructing	a	full	unpruned	tree	and	a	pruned	tree.	Compare	classification	results	of the	pruned	and	unpruned	trees generated.**	
```{r}
install.packages('C50')

library(C50)

#To examine datasets in package C50
data()
```
After examining data function, it has been found out that there are two datasets in 'Customer Churn Data' (C50 package), which are churnTest and churnTrain. To import datasets in C50 package, use command "data(churn)".
```{r}
data(churn)

print("---------------------------Summary Table : churnTrain---------------------")
#To understand dataset churnTrain
summary(churnTrain)
```
```{r}
#Installing package 'rpart' for Decision Tree

install.packages("rpart")

library(rpart)

```
```{r}
#Grow a tree using Rpart to predict customer churn for all other independent variables

fit <- rpart(churn ~ state + account_length + area_code + international_plan + voice_mail_plan + total_day_charge + total_eve_charge + total_night_charge + total_intl_charge + number_vmail_messages + number_customer_service_calls, method="class",data=churnTrain)

#To display result
printcp(fit)

#To plot cross-validation result
plotcp(fit)

#To print detailed summary of splits
summary(fit)

#To plot the tree
plot(fit,uniform = TRUE, main = "Classification of Churn (churnTrain)")
text(fit, use.n = TRUE, all = TRUE, cex = 0.5)
```
```{r}
#Pruning the tree

pfit <- prune(fit, cp=fit$cptable[which.min(fit$cptable[,"xerror"]),"CP"])

#Plot the pruned tree
plot(pfit, uniform = TRUE, main = "Pruned Tree Classification of Churn (churnTrain)")
text(pfit, use.n=TRUE, all = TRUE, cex = 0.5)
```
Pruning the decision tree will help to avoid overfitting the data. It will minimize the cross validation error (uing xerror) and select complexity parameter that is associated with least error. Results shows that unpruned tree is larger because the algorithm is implemented as is. While in pruned tree, there is an additional step which analyse which nodes or branches to be removed that will not affect the performance of decision tree. 

## **Q5 Compare generalisation performance of the pruned and unpruned tree from Q4. Output relevant summaries and confusion matrices. Describe the results.**


